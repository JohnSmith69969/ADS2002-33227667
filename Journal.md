# ADS2002 Individual Portfolio

# Section 1: Weeks 2-6 Reflections

## Week 2
In week 2, we started examining the data for our Monash Solar project. We also watched the video by our coordinator explaining what we were trying to achieve. We are given data from  5 solar pannels at Monash University Clayton from 2018 to 2020. We are also given weather data to work with during that period. Our task is to predict the solar power output in November 2020 based on the previous 2 year's weather and solar pannels data. We initially had alot of trouble in trying to find the data in question. There was some confusion with other projects, so our coordinator did not give us the right data to work with. However after some back and forth we found everything we needed. We firstly realized that our data was not in a csv format, rather a .tsf. This type of file we did not know how change and manipulate, and thus we need to convert it to a .csv in order to be able to continually update the data. We also noticed on the project brief that our data was using UTC time. This will mean that it will record maximum power output in a different timezone. Since we beleive that the time when the sun shines is very important to solar power, we will convert it to AEST (Australian Eastern Standard Time) so that it is in the right timezone. For my part of the project, I just examined some descriptive statistics on the data to check for any "odd" values for different data. I also plotted a scatterplot of solar output over time. There was some weird data, for example for most of 2018 and 2019 did not have continous data for power output. There was clearly some missing values in 2019, but also brief spikes of activity in the solar pannels. The data was continous from November 2019 onwards, however in April-May 2020, there was a weird gap in the data in which it was linearly interpolated.

### Scatterplot of the Different Solar Panels and their Power Output

![image](https://github.com/JohnSmith69969/ADS2002-33227667/assets/126924691/083ef718-b592-4545-8a9a-4244257ed87c)
## Week 3
In week 3, we finished our initial data cleaning that we wanted to do in week 2. We also merged both the weather data and the solar power data into one for each solar panel. This allowed us to corrolate each of the weather variables with power output. As you might imagine, solar intensity was by far the most corrolated with power output, followed by temperature. We also set up GitHub and our project account to store all of our progress together. We realized that there was no NaN values in our data. However clearly there was some strange data pre November 2019. We would see the majority of that year have power output of zero. We realized that we could not just remove zero's from the data, since at nightime there is also zero power output. We thus decided to keep that data for now, until we could remove it without removing a significant amount of our other data. For my part, I did further descriptive analysis of the dataset. I firstly found that there was no significant outliers in the dataset. Everything was relatively close together when you look at the scatterplot. I also realized that during the nighttime the solar panels do not produce any power. This is unexpected, since I would believe that they would charge during the day, and release it during the nightime, but this is clearly not the case.

### Pairplot: Descriptive Analysis of a particular solar panel and the other variables
![image](https://github.com/JohnSmith69969/ADS2002-33227667/assets/126924691/5a993ac6-7221-4860-a937-1e3c5dbbf7e5)


## Week 4
In week 4, I looked at the strange period between April and May, where the data was linearly interpolated. I decided to try out different styles of interpolation to fit the gap better. I realize that the data is more complicated than just linear, since the pattern of solar output is sinusoidal. There is a peak during the day, and a sharp decline at night. I thus used K-Nearest Neighbours interpolation to fit the gap. This model was more complicated than linear regression, and would in theory find the sinusoidal patterns better. It turned out to generate an interpolation no better than linear. This shows that the patterns are too complex or varied for even K-Nearest Neighbours to handle. I therefore decided to tell the group that I would remove that data completely. It was simply distorting our analysis with incorrect and fake data. When I checked the corrolations heatmap of the data again however, it turned out that the corrolations of the variables did not change at all. This meant that the gap was insignificant anyhow. Meanwhile we all made a consecative decision to remove the suspicious data of pre November 2019 from our analysis. We thought that we would remove data up to April 2020 so that all our solar panel data will be in sync. We soon realized that we would miss several months of the year to do our analysis of how the seasons affect the power output. We therefore kept all data after November 2019. 

### Lineplot: Interpolation of gap April-May 2020 using KNN

![image](https://github.com/JohnSmith69969/ADS2002-33227667/assets/126924691/61df2c4c-bac6-4b78-a760-1858b8e0c745)

## Week 5
For Week 5, I did some more descriptive analysis. I managed to graph the daily trend in power output over each day during June 2020. This was just to get a feel for how variable the pattern is for power output. It was definitely highly variability, with substantial fluctuations between different days. But during every night there is always zero power produced. I then graphed the aggregated average power output over each month. You can clearly see that during the summer there is the most power output, and during the winter there is the least. There was some anomalies for April and May, but that was probably since that data had missing values. This shows that despite the variability in our data, there is still definite trends between the seasons. My plot also showed that we did not need to convert our data to AEST, since it was already in AEST. This was lucky that we found this, since otherwise our weather data will be off sync with the solar power data. Meanwhile my other group members experimented with various models to just determine roughly how accurate we could predict the power output based on the weather. Two of my group members got completely different accuracy scores, with one getting 0.2 and another getting 0.8 for multivariate linear regression. This is quite worrying, and it must be the case that either one of them did not fit the data correctly, or they have different data altogether.

### Lineplot: Amount of Power Output Aggregated over Each Month

![image](https://github.com/JohnSmith69969/ADS2002-33227667/assets/126924691/2c263221-f13d-4ede-bc24-c38e39e9a84d)

## Week 6
For week 6, I finished my analysis of power output by comparing a timeseries plot of solar radiation with power output. I realize that infact you can find the maximum power output by mutiplying the efficiency of the panels by their area and solar intensity. This means that solar intensity is linearly dependent on power output. Indeed this could mean that solar intensity will need to be removed from our analysis. Firstly, we cannot measure the importance of the other variables in our data, since that variable will completely dominate the others. It also does not give us any new insights about power output, since power output is calculated directly from solar intensity. Of course we should keep the data for the final model, however to measure the other variables one must remove it. We also quickly checked for any evidence of multicollinearity. In other words, if the feature variables were correlated with each other. In this case, the correlation between different feature variables was not enough to worry about. They did not reach above 0.9 for their correlation score. We need to remove variables of high multicollinearity, since we know that one affects the other in the same way, and as such complicates the model unneccesarily. We finally checked the correlation heatmap for every solar panels to determine their variabity. We found that it was not really very significant.

### Lineplot: Average amount of Solar Radiation Every Month

![image](https://github.com/JohnSmith69969/ADS2002-33227667/assets/126924691/f2d583df-fe51-4911-a914-a7397bcf8391)

# Section 2: Week 6 Reflection

We have firstly learnt to make sure that our data is cleaned and sound before embarking on any descriptive analysis. We have spent six weeks doing data cleaning, and during that time we have converted our data into a suitable format, checked and removed any problematic data, and also checked for "impossible" data in which is an obvious large outlier in the dataset. We have also checked for multicollinearity. I realize how time consuming this process is, but it will improve our analysis significantly. As a team we have collaborated together to tackle different areas of data cleaning seperately. For my part, I did interpolation. One of my group members merged the seperate solar and weather data together into one dataframe. This allows us to analyse the data in depth in multiple areas to check for any problems with our dataset, and not focus on just one area. I have also learnt how to listen to change my approach by listening to others. I was proposing to remove the data up to April 2020, however my other team members told me that that would remove data from the previous months. I listened and decided to keep that data. 

There were significant challanges in the data cleaning process. Firstly, we needed to change our file to .csv from .tsf. This was due to the annoying fact you cannot modify the .tsf file. This requires us to research how to do this on the internet. We also had to try and make the solar data be in a useful format. This included changing the index to DateTime, and rearranging the actual data so that it was in seperate columns rather than being all in one row. We also needed to understand what the data was actually telling us and which was actually useful for our project. We needed to research the document shown to us about the data, as the actual names in our data did not tell us anything. Finally, we needed to make sure that our power output data matched exactly with the weather data. To do this, we averaged the power output every 15 minutes, since the weather data was also every 15 minutes. Therefore, both of the dataframes aligned.

My contribution to the project mainly included descriptive analysis and interpolation. For descriptive analysis, I analysed how the power output changed depending on the time of day and season, meaning that we could analyse how varied the data was, and also we could definitely see that power output was affected by the season. I also analysed how I could interpolate missing values in the data. I concluded that it was just too hard to achieve with our available models, and thus we simply removed the data for that period. I also breifly checked for multicollinearity between different variables, and showed that solar intensity was really just the max power output. I also performed general descriptive analysis on all the data to check for any variance.

I think that we should have a definite plan for what we will achieve every week. Indeed, we should together focus on analysing different


